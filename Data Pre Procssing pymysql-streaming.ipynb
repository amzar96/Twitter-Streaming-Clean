{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np, pylab as pl\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import pymysql\n",
    "import pymysql.cursors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dummy values \n",
    "conn = pymysql.connect(host='localhost', port=3306, user='root', use_unicode=True, passwd='admin1234', db='tweet',charset='utf8')\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        query = \"SELECT * FROM tweetdata \"\n",
    "        df = pd.read_sql(query, conn)\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traffic,jammed,\n",
    "\n",
    "#df[\"label\"] = \"\" #lavel column assign\n",
    "df['text'] = df['text'].str.replace('@',' ') #remove @ \n",
    "df = df[df.text.str.contains(\"rt\" or \"RT\") == False] #remove RT\n",
    "\n",
    "remlink = []\n",
    "for i in df['text']:\n",
    "    a = re.sub(r\"http\\S+\", \"\", i)\n",
    "    remlink.append(a)\n",
    "    \n",
    "df['text'] = remlink #update TEXT after remove LINK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New df for remove tweet not according to keywords\n",
    "\n",
    "dfkeyword = df[df.text.str.contains(\"hujan | traffic slow| slow | traffic jammed | accident | stuck\")]\n",
    "dfkeyword=dfkeyword.reset_index()\n",
    "#dfkeyword = df[df.text.str.contains(\"makan\") == True]\n",
    "#dfkeyword = df[df.text.str.contains(\"hujan\") == True]\n",
    "\n",
    "del dfkeyword['index'] #del default index col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkeyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Malay Stop Word ONLY\n",
    "\n",
    "\n",
    "stop_words = set({'ada','inikah','sampai','adakah','inilah','sana','adakan','itu','sangat','adalah','itukah','sangatlah','adanya','itulah','saya','adapun','jadi','se','agak','jangan','seandainya','agar','janganlah','sebab','akan','jika','sebagai','aku','jikalau','sebagaimana','akulah','jua','sebanyak','akupun','juapun','sebelum','al','juga','sebelummu','alangkah','kalau','sebelumnya','allah','kami','sebenarnya','amat','kamikah','secara','antara','kamipun','sedang','antaramu','kamu','sedangkan','antaranya','kamukah','sedikit','apa','kamupun','sedikitpun','apa-apa','katakan','segala','apabila','ke','sehingga','apakah','kecuali','sejak','apapun','kelak','sekalian','atas','kembali','sekalipun','atasmu','kemudian','sekarang','atasnya','kepada','sekitar','atau','kepadaku','selain','ataukah','kepadakulah','selalu','ataupun','kepadamu','selama','bagaimana','kepadanya','selama-lamanya','bagaimanakah','kepadanyalah','seluruh','bagi','kerana','seluruhnya','bagimu','kerananya','sementara','baginya','kesan','semua','bahawa','ketika','semuanya','bahawasanya','kini','semula','bahkan','kita','senantiasa','bahwa','ku','sendiri','banyak','kurang','sentiasa','banyaknya','lagi','seolah','barangsiapa','lain','seolah-olah','bawah','lalu','seorangpun','beberapa','lamanya','separuh','begitu','langsung','sepatutnya','begitupun','lebih','seperti','belaka','maha','seraya','belum','mahu','sering','belumkah','mahukah','serta','berada','mahupun','seseorang','berapa','maka','sesiapa','berikan','malah','sesuatu','beriman','mana','sesudah','berkenaan','manakah','sesudahnya','berupa','manapun','sesungguhnya','beserta','masih','sesungguhnyakah','biarpun','masing','setelah','bila','masing-masing','setiap','bilakah','melainkan','siapa','bilamana','memang','siapakah','bisa','mempunyai','sini','boleh','mendapat','situ','bukan','mendapati','situlah','bukankah','mendapatkan','suatu','bukanlah','mengadakan','sudah','dahulu','mengapa','sudahkah','dalam','mengapakah','sungguh','dalamnya','mengenai','sungguhpun','dan','menjadi','supaya','dapat','menyebabkan','tadinya','dapati','menyebabkannya','tahukah','dapatkah','mereka','tak','dapatlah','merekalah','tanpa','dari','merekapun','tanya','daripada','meskipun','tanyakanlah','daripadaku','mu','tapi','daripadamu','nescaya','telah','daripadanya','niscaya','tentang','demi','nya','tentu','demikian','olah','terdapat','demikianlah','oleh','terhadap','dengan','orang','terhadapmu','dengannya','pada','termasuk','di','padahal','terpaksa','dia','padamu','tertentu','dialah','padanya','tetapi','didapat','paling','tiada','didapati','para','tiadakah','dimanakah','pasti','tiadalah','engkau','patut','tiap','engkaukah','patutkah','tiap-tiap','engkaulah','per','tidak','engkaupun','pergilah','tidakkah','hai','perkara','tidaklah','hampir','perkaranya','turut','hampir-hampir','perlu','untuk','hanya','pernah','untukmu','hanyalah','pertama','wahai','hendak','pula','walau','hendaklah','pun','walaupun','hingga','sahaja','ya','ia','saja','yaini','iaitu','saling','yaitu','ialah','sama','yakni','ianya','yang','inginkah','samakah','ini','sambil'})\n",
    "\n",
    "\n",
    "c = []\n",
    "\n",
    "for word in dfkeyword['text']:\n",
    "    word=word.lower()\n",
    "    word_tokens = word_tokenize(word)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    if word not in stop_words:        \n",
    "        filtered_sentence.append(word)\n",
    "        a=\" \".join( filtered_sentence )\n",
    "        c.append(a)\n",
    "\n",
    "    \n",
    "dfkeyword['text'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : pahal la lemah sgt antibody ni . kene hujan sikit dh selsema la , demam la pahal la lemah sgt antibody ni . kene hujan sikit dh selsema la , demam la pahal la lemah sgt antibody ni . kene hujan sikit dh selsema la , demam la pahal la lemah sgt antibody ni. kene hujan sikit dh selsema la, demam la\n",
      "1 ... 00\n",
      "\n",
      "\n",
      "2 : semalam cari baju hujan dekat petron , kat cashier baju hujan ? tunjuk arah peti minuman . blur… semalam cari baju hujan dekat petron , kat cashier baju hujan ? tunjuk arah peti minuman . blur… semalam cari baju hujan dekat petron , kat cashier baju hujan ? tunjuk arah peti minuman . blur… semalam cari baju hujan dekat petron, tanya kat cashier ada baju hujan tak? dia tunjuk arah peti minuman. aku blur… \n",
      "1 ... 01\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Insert class label (1 - yes | 0 - no)\n",
    "\n",
    "yn =[]\n",
    "count=1\n",
    "for i in dfkeyword['text'] :\n",
    "    print(\"{} : {}\".format(count,i))\n",
    "    yon = int(input(\"1 ... 0\"))\n",
    "    print(\"\\n\")\n",
    "    yn.append(yon)\n",
    "    count+=1\n",
    "    \n",
    "dfkeyword['label'] = yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfkeyword.to_csv('data/tweet-label-class.csv', encoding='utf-8',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"UPDATE tweetdata SET  (`text`)=%s, (`label`)=%s \", (dfkeyword['text'], dfkeyword['label']))\n",
    "\n",
    "cur.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
